{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"NLP_Enco.ipynb","provenance":[],"mount_file_id":"1ZNUBXAb0TPapw6hHVKxnd7MDJyp-ZElh","authorship_tag":"ABX9TyPumFwJMrhXoHF53f1QKgIK"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"Ze0qW9m5DzIi","executionInfo":{"status":"ok","timestamp":1603634694514,"user_tz":-360,"elapsed":2567,"user":{"displayName":"JOY PAUL","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjtAXIR8xWrSQkgqla_ZQhAmp7-3aHEUv5wEncTbw=s64","userId":"08034521466942635406"}}},"source":["import collections\n","import numpy as np\n","import pandas as pd\n","from keras.preprocessing.text import Tokenizer\n","from keras.preprocessing.sequence import pad_sequences\n","from keras.models import Model\n","from keras.layers import GRU, Input, Dense, TimeDistributed, Activation, RepeatVector, Bidirectional\n","from keras.layers.embeddings import Embedding\n","from keras.optimizers import Adam\n","from keras.losses import sparse_categorical_crossentropy"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"L0CliGmJD_HA","executionInfo":{"status":"ok","timestamp":1603634696305,"user_tz":-360,"elapsed":1186,"user":{"displayName":"JOY PAUL","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjtAXIR8xWrSQkgqla_ZQhAmp7-3aHEUv5wEncTbw=s64","userId":"08034521466942635406"}}},"source":["import os\n","\n","def load_data(path):\n","    \"\"\"\n","    Load dataset\n","    \"\"\"\n","    input_file = os.path.join(path)\n","    with open(input_file, \"r\", encoding ='utf=8') as f:\n","        data = f.read()\n","\n","    return data.split('\\n')\n","\n","\n","from keras.losses import sparse_categorical_crossentropy\n","from keras.models import Sequential\n","from keras.preprocessing.text import Tokenizer\n","from keras.utils import to_categorical\n","\n","\n","def _test_model(model, input_shape, output_sequence_length, french_vocab_size):\n","    if isinstance(model, Sequential):\n","        model = model.model\n","\n","    assert model.input_shape == (None, *input_shape[1:]),'Wrong input shape. Found input shape {} using parameter input_shape={}'.format(model.input_shape, input_shape)\n","\n","    assert model.output_shape == (None, output_sequence_length, french_vocab_size),'Wrong output shape. Found output shape {} using parameters output_sequence_length={} and french_vocab_size={}'.format(model.output_shape, output_sequence_length, french_vocab_size)\n","\n","    assert len(model.loss_functions) > 0,'No loss function set.  Apply the `compile` function to the model.'\n","\n","    assert sparse_categorical_crossentropy in model.loss_functions,'Not using `sparse_categorical_crossentropy` function for loss.'\n","\n","\n","def test_tokenize(tokenize):\n","    sentences = [\n","        'আমি এই উপন্যাস আগেও পড়েছি।',\n","        'টম খুব খোলামেলা মানুষ।',\n","        'তুমি কি কখনো হেলিকপ্টারে বসেছো?']\n","    tokenized_sentences, tokenizer = tokenize(sentences)\n","    assert tokenized_sentences == tokenizer.texts_to_sequences(sentences),\\\n","        'Tokenizer returned and doesn\\'t generate the same sentences as the tokenized sentences returned. '\n","\n","\n","def test_pad(pad):\n","    tokens = [\n","        [i for i in range(4)],\n","        [i for i in range(6)],\n","        [i for i in range(3)]]\n","    padded_tokens = pad(tokens)\n","    padding_id = padded_tokens[0][-1]\n","    true_padded_tokens = np.array([\n","        [i for i in range(4)] + [padding_id]*2,\n","        [i for i in range(6)],\n","        [i for i in range(3)] + [padding_id]*3])\n","    assert isinstance(padded_tokens, np.ndarray),\\\n","        'Pad returned the wrong type.  Found {} type, expected numpy array type.'\n","    assert np.all(padded_tokens == true_padded_tokens), 'Pad returned the wrong results.'\n","\n","    padded_tokens_using_length = pad(tokens, 9)\n","    assert np.all(padded_tokens_using_length == np.concatenate((true_padded_tokens, np.full((3, 3), padding_id)), axis=1)),\\\n","        'Using length argument return incorrect results'\n","\n","\n","def test_simple_model(simple_model):\n","    input_shape = (80000, 17, 1)\n","    output_sequence_length = 17\n","    english_vocab_size = 12201\n","    french_vocab_size = 14157\n","\n","    model = simple_model(input_shape, output_sequence_length, english_vocab_size, french_vocab_size)\n","    _test_model(model, input_shape, output_sequence_length, french_vocab_size)\n","\n","\n","def test_embed_model(embed_model):\n","    input_shape = (200000, 17)\n","    output_sequence_length = 17\n","    english_vocab_size = 12201\n","    french_vocab_size = 14157\n","\n","    model = embed_model(input_shape, output_sequence_length, english_vocab_size, french_vocab_size)\n","    _test_model(model, input_shape, output_sequence_length, french_vocab_size)\n","\n","\n","def test_encdec_model(encdec_model):\n","    input_shape = (200000, 17, 1)\n","    output_sequence_length = 17\n","    english_vocab_size = 12201\n","    french_vocab_size = 14157\n","\n","    model = encdec_model(input_shape, output_sequence_length, english_vocab_size, french_vocab_size)\n","    _test_model(model, input_shape, output_sequence_length, french_vocab_size)\n","\n","\n","def test_bd_model(bd_model):\n","    input_shape = (200000, 17, 1)\n","    output_sequence_length = 17\n","    english_vocab_size = 12201\n","    french_vocab_size = 14157\n","\n","    model = bd_model(input_shape, output_sequence_length, english_vocab_size, french_vocab_size)\n","    _test_model(model, input_shape, output_sequence_length, french_vocab_size)\n","\n","\n","def test_model_final(model_final):\n","    input_shape = (200000, 17)\n","    output_sequence_length = 17\n","    english_vocab_size = 12201\n","    french_vocab_size = 14157\n","\n","    model = model_final(input_shape, output_sequence_length, english_vocab_size, french_vocab_size)\n","    _test_model(model, input_shape, output_sequence_length, french_vocab_size)"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"FNY2QibaD_UO","executionInfo":{"status":"ok","timestamp":1603634702722,"user_tz":-360,"elapsed":2850,"user":{"displayName":"JOY PAUL","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjtAXIR8xWrSQkgqla_ZQhAmp7-3aHEUv5wEncTbw=s64","userId":"08034521466942635406"}},"outputId":"af6c1cf0-3127-491d-8845-0e15a940f5af","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["english_sentences = load_data('/content/drive/My Drive/NLP_csv/80kban.txt')\n","french_sentences = load_data('/content/drive/My Drive/NLP_csv/80kger.txt')\n","print('Dataset Loaded')"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Dataset Loaded\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"R_42CWceD_f2","executionInfo":{"status":"ok","timestamp":1603634702725,"user_tz":-360,"elapsed":1845,"user":{"displayName":"JOY PAUL","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjtAXIR8xWrSQkgqla_ZQhAmp7-3aHEUv5wEncTbw=s64","userId":"08034521466942635406"}},"outputId":"d627b7ff-b2d6-4a9b-f72e-8c7a7b086fe4","colab":{"base_uri":"https://localhost:8080/","height":87}},"source":["for sample_i in range(2):\n","    print('small_vocab_en Line {}:  {}'.format(sample_i + 1, english_sentences[sample_i]))\n","    print('small_vocab_fr Line {}:  {}'.format(sample_i + 1, french_sentences[sample_i]))"],"execution_count":4,"outputs":[{"output_type":"stream","text":["small_vocab_en Line 1:  যান.\n","small_vocab_fr Line 1:  Geh.\n","small_vocab_en Line 2:  নমস্কার!\n","small_vocab_fr Line 2:  Hallo!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mYosvMLlD_r5","executionInfo":{"status":"ok","timestamp":1603634703259,"user_tz":-360,"elapsed":1354,"user":{"displayName":"JOY PAUL","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjtAXIR8xWrSQkgqla_ZQhAmp7-3aHEUv5wEncTbw=s64","userId":"08034521466942635406"}},"outputId":"ee2725bb-1e3b-4378-8ab6-2eafda587021","colab":{"base_uri":"https://localhost:8080/","height":176}},"source":["english_words_counter = collections.Counter([word for sentence in english_sentences for word in sentence.split()])\n","french_words_counter = collections.Counter([word for sentence in french_sentences for word in sentence.split()])\n","print('{} English words.'.format(len([word for sentence in english_sentences for word in sentence.split()])))\n","print('{} unique English words.'.format(len(english_words_counter)))\n","print('10 Most common words in the English dataset:')\n","print('\"' + '\" \"'.join(list(zip(*english_words_counter.most_common(10)))[0]) + '\"')\n","print()\n","print('{} French words.'.format(len([word for sentence in french_sentences for word in sentence.split()])))\n","print('{} unique French words.'.format(len(french_words_counter)))\n","print('10 Most common words in the French dataset:')\n","print('\"' + '\" \"'.join(list(zip(*french_words_counter.most_common(10)))[0]) + '\"')"],"execution_count":5,"outputs":[{"output_type":"stream","text":["335708 English words.\n","14101 unique English words.\n","10 Most common words in the English dataset:\n","\"আমি\" \"টম\" \"এটা\" \"কি\" \"তুমি\" \"আমার\" \"না।\" \"তোমার\" \"সে\" \"একটা\"\n","\n","356660 French words.\n","23231 unique French words.\n","10 Most common words in the French dataset:\n","\"Tom\" \"Ich\" \"ist\" \"Sie\" \"nicht\" \"das\" \"du\" \"Das\" \"hat\" \"Er\"\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"iOxtqBBoD_5o","executionInfo":{"status":"ok","timestamp":1603634706287,"user_tz":-360,"elapsed":1123,"user":{"displayName":"JOY PAUL","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjtAXIR8xWrSQkgqla_ZQhAmp7-3aHEUv5wEncTbw=s64","userId":"08034521466942635406"}},"outputId":"a2ff60fe-9cb1-4b18-87e5-fa6335980760","colab":{"base_uri":"https://localhost:8080/","height":232}},"source":["def tokenize(x):\n","    x_tk = Tokenizer(char_level = False)\n","    x_tk.fit_on_texts(x)\n","    return x_tk.texts_to_sequences(x), x_tk\n","text_sentences = [\n","    'আমি এই উপন্যাস আগেও পড়েছি।',\n","    'টম খুব খোলামেলা মানুষ।',\n","    'তুমি কি কখনো হেলিকপ্টারে বসেছো?']\n","text_tokenized, text_tokenizer = tokenize(text_sentences)\n","print(text_tokenizer.word_index)\n","print()\n","for sample_i, (sent, token_sent) in enumerate(zip(text_sentences, text_tokenized)):\n","    print('Sequence {} in x'.format(sample_i + 1))\n","    print('  Input:  {}'.format(sent))\n","    print('  Output: {}'.format(token_sent))"],"execution_count":6,"outputs":[{"output_type":"stream","text":["{'আমি': 1, 'এই': 2, 'উপন্যাস': 3, 'আগেও': 4, 'পড়েছি।': 5, 'টম': 6, 'খুব': 7, 'খোলামেলা': 8, 'মানুষ।': 9, 'তুমি': 10, 'কি': 11, 'কখনো': 12, 'হেলিকপ্টারে': 13, 'বসেছো': 14}\n","\n","Sequence 1 in x\n","  Input:  আমি এই উপন্যাস আগেও পড়েছি।\n","  Output: [1, 2, 3, 4, 5]\n","Sequence 2 in x\n","  Input:  টম খুব খোলামেলা মানুষ।\n","  Output: [6, 7, 8, 9]\n","Sequence 3 in x\n","  Input:  তুমি কি কখনো হেলিকপ্টারে বসেছো?\n","  Output: [10, 11, 12, 13, 14]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jQs3PltkEAFu","executionInfo":{"status":"ok","timestamp":1603634709374,"user_tz":-360,"elapsed":968,"user":{"displayName":"JOY PAUL","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjtAXIR8xWrSQkgqla_ZQhAmp7-3aHEUv5wEncTbw=s64","userId":"08034521466942635406"}},"outputId":"7f1f9413-a2b9-4a50-b566-f22531abcbd0","colab":{"base_uri":"https://localhost:8080/","height":176}},"source":["# import project_tests as tests\n","def pad(x, length=None):\n","    if length is None:\n","        length = max([len(sentence) for sentence in x])\n","    return pad_sequences(x, maxlen = length, padding = 'post')\n","test_pad(pad)\n","# Pad Tokenized output\n","test_pad = pad(text_tokenized)\n","for sample_i, (token_sent, pad_sent) in enumerate(zip(text_tokenized, test_pad)):\n","    print('Sequence {} in x'.format(sample_i + 1))\n","    print('  Input:  {}'.format(np.array(token_sent)))\n","    print('  Output: {}'.format(pad_sent))"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Sequence 1 in x\n","  Input:  [1 2 3 4 5]\n","  Output: [1 2 3 4 5]\n","Sequence 2 in x\n","  Input:  [6 7 8 9]\n","  Output: [6 7 8 9 0]\n","Sequence 3 in x\n","  Input:  [10 11 12 13 14]\n","  Output: [10 11 12 13 14]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Z9HH4vl3EASK","executionInfo":{"status":"ok","timestamp":1603634717608,"user_tz":-360,"elapsed":5018,"user":{"displayName":"JOY PAUL","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjtAXIR8xWrSQkgqla_ZQhAmp7-3aHEUv5wEncTbw=s64","userId":"08034521466942635406"}},"outputId":"7b763d06-5e53-4b64-8ba5-059975aae0f1","colab":{"base_uri":"https://localhost:8080/","height":105}},"source":["def preprocess(x, y):\n","    preprocess_x, x_tk = tokenize(x)\n","    preprocess_y, y_tk = tokenize(y)\n","    preprocess_x = pad(preprocess_x)\n","    preprocess_y = pad(preprocess_y)\n","    # Keras's sparse_categorical_crossentropy function requires the labels to be in 3 dimensions\n","    preprocess_y = preprocess_y.reshape(*preprocess_y.shape, 1)\n","    return preprocess_x, preprocess_y, x_tk, y_tk\n","\n","preproc_english_sentences, preproc_french_sentences, english_tokenizer, french_tokenizer = preprocess(english_sentences, french_sentences)    \n","max_english_sequence_length = preproc_english_sentences.shape[1]\n","max_french_sequence_length = preproc_french_sentences.shape[1]\n","english_vocab_size = len(english_tokenizer.word_index)\n","french_vocab_size = len(french_tokenizer.word_index)\n","print('Data Preprocessed')\n","print(\"Max English sentence length:\", max_english_sequence_length)\n","print(\"Max French sentence length:\", max_french_sequence_length)\n","print(\"English vocabulary size:\", english_vocab_size)\n","print(\"French vocabulary size:\", french_vocab_size)"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Data Preprocessed\n","Max English sentence length: 17\n","Max French sentence length: 17\n","English vocabulary size: 12201\n","French vocabulary size: 14157\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tzJGaxGyEAeH","executionInfo":{"status":"ok","timestamp":1603634718938,"user_tz":-360,"elapsed":1325,"user":{"displayName":"JOY PAUL","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjtAXIR8xWrSQkgqla_ZQhAmp7-3aHEUv5wEncTbw=s64","userId":"08034521466942635406"}},"outputId":"0d7c11f3-4364-47fe-b4df-c8fb63c3fa4a","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["def logits_to_text(logits, tokenizer):\n","    index_to_words = {id: word for word, id in tokenizer.word_index.items()}\n","    index_to_words[0] = '<PAD>'\n","    return ' '.join([index_to_words[prediction] for prediction in np.argmax(logits, 1)])\n","print('`logits_to_text` function loaded.')"],"execution_count":9,"outputs":[{"output_type":"stream","text":["`logits_to_text` function loaded.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2BieEpSDEAq3","executionInfo":{"status":"ok","timestamp":1603657095981,"user_tz":-360,"elapsed":22373676,"user":{"displayName":"JOY PAUL","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjtAXIR8xWrSQkgqla_ZQhAmp7-3aHEUv5wEncTbw=s64","userId":"08034521466942635406"}},"outputId":"42da2daa-7ded-43bb-b369-1ee30cf731f8","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["def encdec_model(input_shape, output_sequence_length, english_vocab_size, french_vocab_size):\n","  \n","    learning_rate = 1e-2\n","    model = Sequential()\n","    model.add(GRU(128, input_shape = input_shape[1:], return_sequences = False))\n","    model.add(RepeatVector(output_sequence_length))\n","    model.add(GRU(128, return_sequences = True))\n","    model.add(TimeDistributed(Dense(french_vocab_size, activation = 'softmax')))\n","    \n","    model.compile(loss = sparse_categorical_crossentropy, \n","                 optimizer = Adam(learning_rate), \n","                 metrics = ['accuracy'])\n","    return model\n","# tests.test_encdec_model(encdec_model)\n","tmp_x = pad(preproc_english_sentences)\n","tmp_x = tmp_x.reshape((-1, preproc_english_sentences.shape[1], 1))\n","encodeco_model = encdec_model(\n","    tmp_x.shape,\n","    preproc_french_sentences.shape[1],\n","    len(english_tokenizer.word_index)+1,\n","    len(french_tokenizer.word_index)+1)\n","encodeco_model.fit(tmp_x, preproc_french_sentences, batch_size=100, epochs=30, validation_split=0.2)\n","print(logits_to_text(encodeco_model.predict(tmp_x[:1])[0], french_tokenizer))"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Epoch 1/30\n","640/640 [==============================] - 748s 1s/step - loss: 2.0117 - accuracy: 0.7633 - val_loss: 2.4196 - val_accuracy: 0.7116\n","Epoch 2/30\n","640/640 [==============================] - 741s 1s/step - loss: 1.6555 - accuracy: 0.7750 - val_loss: 1.9843 - val_accuracy: 0.7274\n","Epoch 3/30\n","640/640 [==============================] - 741s 1s/step - loss: 1.4680 - accuracy: 0.7866 - val_loss: 1.9260 - val_accuracy: 0.7336\n","Epoch 4/30\n","640/640 [==============================] - 741s 1s/step - loss: 1.4137 - accuracy: 0.7918 - val_loss: 1.8956 - val_accuracy: 0.7376\n","Epoch 5/30\n","640/640 [==============================] - 751s 1s/step - loss: 1.3783 - accuracy: 0.7947 - val_loss: 1.8930 - val_accuracy: 0.7383\n","Epoch 6/30\n","640/640 [==============================] - 747s 1s/step - loss: 1.3555 - accuracy: 0.7962 - val_loss: 1.8695 - val_accuracy: 0.7394\n","Epoch 7/30\n","640/640 [==============================] - 741s 1s/step - loss: 1.3305 - accuracy: 0.7979 - val_loss: 1.8626 - val_accuracy: 0.7403\n","Epoch 8/30\n","640/640 [==============================] - 743s 1s/step - loss: 1.3130 - accuracy: 0.7989 - val_loss: 1.8557 - val_accuracy: 0.7424\n","Epoch 9/30\n","640/640 [==============================] - 747s 1s/step - loss: 1.2999 - accuracy: 0.8002 - val_loss: 1.8613 - val_accuracy: 0.7431\n","Epoch 10/30\n","640/640 [==============================] - 749s 1s/step - loss: 1.2930 - accuracy: 0.8012 - val_loss: 1.8592 - val_accuracy: 0.7433\n","Epoch 11/30\n","640/640 [==============================] - 744s 1s/step - loss: 1.2776 - accuracy: 0.8020 - val_loss: 1.8614 - val_accuracy: 0.7443\n","Epoch 12/30\n","640/640 [==============================] - 744s 1s/step - loss: 1.2727 - accuracy: 0.8028 - val_loss: 1.8450 - val_accuracy: 0.7464\n","Epoch 13/30\n","640/640 [==============================] - 743s 1s/step - loss: 1.2576 - accuracy: 0.8034 - val_loss: 1.8422 - val_accuracy: 0.7455\n","Epoch 14/30\n","640/640 [==============================] - 748s 1s/step - loss: 1.2492 - accuracy: 0.8041 - val_loss: 1.8489 - val_accuracy: 0.7460\n","Epoch 15/30\n","640/640 [==============================] - 749s 1s/step - loss: 1.2447 - accuracy: 0.8045 - val_loss: 1.8571 - val_accuracy: 0.7447\n","Epoch 16/30\n","640/640 [==============================] - 742s 1s/step - loss: 1.2386 - accuracy: 0.8049 - val_loss: 1.8603 - val_accuracy: 0.7455\n","Epoch 17/30\n","640/640 [==============================] - 741s 1s/step - loss: 1.2288 - accuracy: 0.8053 - val_loss: 1.8697 - val_accuracy: 0.7461\n","Epoch 18/30\n","640/640 [==============================] - 741s 1s/step - loss: 1.2229 - accuracy: 0.8055 - val_loss: 1.8588 - val_accuracy: 0.7466\n","Epoch 19/30\n","640/640 [==============================] - 745s 1s/step - loss: 1.2168 - accuracy: 0.8061 - val_loss: 1.8412 - val_accuracy: 0.7478\n","Epoch 20/30\n","640/640 [==============================] - 748s 1s/step - loss: 1.2135 - accuracy: 0.8060 - val_loss: 1.8502 - val_accuracy: 0.7462\n","Epoch 21/30\n","640/640 [==============================] - 747s 1s/step - loss: 1.2100 - accuracy: 0.8063 - val_loss: 1.8498 - val_accuracy: 0.7474\n","Epoch 22/30\n","640/640 [==============================] - 746s 1s/step - loss: 1.2062 - accuracy: 0.8064 - val_loss: 1.8470 - val_accuracy: 0.7483\n","Epoch 23/30\n","640/640 [==============================] - 741s 1s/step - loss: 1.2007 - accuracy: 0.8069 - val_loss: 1.8614 - val_accuracy: 0.7483\n","Epoch 24/30\n","640/640 [==============================] - 748s 1s/step - loss: 1.1979 - accuracy: 0.8071 - val_loss: 1.8375 - val_accuracy: 0.7485\n","Epoch 25/30\n","640/640 [==============================] - 747s 1s/step - loss: 1.1953 - accuracy: 0.8072 - val_loss: 1.8365 - val_accuracy: 0.7487\n","Epoch 26/30\n","640/640 [==============================] - 741s 1s/step - loss: 1.1949 - accuracy: 0.8071 - val_loss: 1.8283 - val_accuracy: 0.7489\n","Epoch 27/30\n","640/640 [==============================] - 741s 1s/step - loss: 1.1908 - accuracy: 0.8071 - val_loss: 1.8392 - val_accuracy: 0.7486\n","Epoch 28/30\n","640/640 [==============================] - 740s 1s/step - loss: 1.1904 - accuracy: 0.8073 - val_loss: 1.8449 - val_accuracy: 0.7484\n","Epoch 29/30\n","640/640 [==============================] - 752s 1s/step - loss: 1.1874 - accuracy: 0.8073 - val_loss: 1.8385 - val_accuracy: 0.7492\n","Epoch 30/30\n","640/640 [==============================] - 742s 1s/step - loss: 1.1847 - accuracy: 0.8077 - val_loss: 1.8379 - val_accuracy: 0.7491\n","das ist <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mrMxsNdGEA2p","executionInfo":{"status":"error","timestamp":1603661096961,"user_tz":-360,"elapsed":1160,"user":{"displayName":"JOY PAUL","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjtAXIR8xWrSQkgqla_ZQhAmp7-3aHEUv5wEncTbw=s64","userId":"08034521466942635406"}},"outputId":"49b340b0-e530-4546-b3e5-7192c9d4f747","colab":{"base_uri":"https://localhost:8080/","height":761}},"source":["def final_predictions(x, y, x_tk, y_tk):\n","    y_id_to_word = {value: key for key, value in y_tk.word_index.items()}\n","    y_id_to_word[0] = '<PAD>'\n","    sentence = ''\n","    sentence = [x_tk.word_index[word] for word in sentence.split()]\n","    debug1 = sentence\n","    sentence = pad_sequences([sentence], maxlen=x.shape[-1], padding='post')\n","    debug2 = sentence\n","    sentences = np.array([sentence[0], x[0]])\n","    debug3 = sentences\n","    predictions = encodeco_model.predict(sentences, len(sentences))\n","    debug4 = predictions\n","    print('Sample 1:')\n","    print(' '.join([y_id_to_word[np.argmax(x)] for x in predictions[0]]))\n","    print('ওহে')\n","    print('Sample 2:')\n","    print(' '.join([y_id_to_word[np.argmax(x)] for x in predictions[1]]))\n","    print(' '.join([y_id_to_word[np.max(x)] for x in y[1209]]))\n","    a = []\n","    for i in range(0,len(french_sentences)):\n","        debug5 = \" \".join([y_id_to_word[np.max(x)] for x in y[i]])\n","        if i  == 1:\n","            debug4 = debug5\n","        a.append(debug5)        \n","    from pandas import DataFrame\n","    df = DataFrame(a,columns=[\"predicted string\"])\n","    df[\"predicted string\"]= df[\"predicted string\"].str.replace(\"<PAD>\", \"\", case = False) \n","    df[\"actual language\"] = french_sentences\n","\n","    \n","    return debug1, debug2, debug3, debug4, debug5, a, df\n","debug1, debug2, debug3, debug4, debug5,  a, df = final_predictions(preproc_english_sentences, preproc_french_sentences, english_tokenizer, french_tokenizer)\n","#df.to_csv(\"jekhane khushi save kore ne sagol.csv\")"],"execution_count":16,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-16-140c3ea3e0e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdebug1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mdebug1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug5\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinal_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreproc_english_sentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreproc_french_sentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menglish_tokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrench_tokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;31m#df.to_csv(\"jekhane khushi save kore ne sagol.csv\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-16-140c3ea3e0e5>\u001b[0m in \u001b[0;36mfinal_predictions\u001b[0;34m(x, y, x_tk, y_tk)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mdebug3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencodeco_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mdebug4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Sample 1:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m       raise ValueError('{} is not supported in multi-worker mode.'.format(\n\u001b[1;32m    129\u001b[0m           method.__name__))\n\u001b[0;32m--> 130\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m   return tf_decorator.make_decorator(\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1597\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1598\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1599\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1600\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1601\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    812\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 814\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    815\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2826\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2828\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2829\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3208\u001b[0m           \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_signature\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3209\u001b[0m           and call_context_key in self._function_cache.missed):\n\u001b[0;32m-> 3210\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_define_function_with_shape_relaxation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_define_function_with_shape_relaxation\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3141\u001b[0m     graph_function = self._create_graph_function(\n\u001b[0;32m-> 3142\u001b[0;31m         args, kwargs, override_flat_arg_shapes=relaxed_arg_shapes)\n\u001b[0m\u001b[1;32m   3143\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marg_relaxed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrank_only_cache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3073\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3074\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3075\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3076\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3077\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    598\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    601\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    971\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 973\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    974\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1462 predict_function  *\n        return step_function(self, iterator)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1452 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1445 run_step  **\n        outputs = model.predict_step(data)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1418 predict_step\n        return self(x, training=False)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py:976 __call__\n        self.name)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/input_spec.py:180 assert_input_compatibility\n        str(x.shape.as_list()))\n\n    ValueError: Input 0 of layer sequential is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: [2, 17]\n"]}]},{"cell_type":"code","metadata":{"id":"-HjSUHeBEBBY","executionInfo":{"status":"error","timestamp":1603657128876,"user_tz":-360,"elapsed":1121,"user":{"displayName":"JOY PAUL","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjtAXIR8xWrSQkgqla_ZQhAmp7-3aHEUv5wEncTbw=s64","userId":"08034521466942635406"}},"outputId":"bb399c9e-c3ca-4bf2-d733-ee9c6962cdc3","colab":{"base_uri":"https://localhost:8080/","height":167}},"source":["df_test = df"],"execution_count":11,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-acd85818180f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"]}]},{"cell_type":"code","metadata":{"id":"otQwkzc4EBNh"},"source":["remove_characters = [\"?\", \".\",\"!\",\",\"]\n","\n","for c in remove_characters:\n","    df_test[\"actual language\"] =  df_test[\"actual language\"].str.replace(c,\"\")\n","\n","df_test[\"actual language\"] = df_test[\"actual language\"] .str.lower()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ueGtMLh1EBb_"},"source":["df_test"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"75mn7RxwEBoY"},"source":["col_1 = df['predicted string'].tolist()\n","col_2 = df[\"actual language\"].tolist()\n","\n","\n","from nltk.translate.bleu_score import corpus_bleu\n","#reference = [['this', 'is', 'a', 'test'], ['this', 'is' 'test']]\n","#candidate = ['this', 'is', 'a', 'test']\n","score1 = corpus_bleu(col_2, col_1, weights=(1, 0, 0, 0))\n","score2 = corpus_bleu(col_2, col_1, weights=(0.5, 0.5, 0, 0))\n","score3 = corpus_bleu(col_2, col_1, weights=(0.33, 0.33, 0.33, 0))\n","score4 = corpus_bleu(col_2, col_1, weights=(0.25, 0.25, 0.25, 0.25))\n","score21 = corpus_bleu(col_2, col_1, weights=(0.5, 0.5, 0, 0))\n","score31 = corpus_bleu(col_2, col_1, weights=(0.33, 0.33, 0.33, 0))\n","score41 = corpus_bleu(col_2, col_1, weights=(0.25, 0.25, 0.25, 0.25))\n","print(score1)\n","print(score2)\n","print(score3)\n","print(score4)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vE7mKtn7EuHZ"},"source":["score11 = corpus_bleu(col_2, col_1, weights=(1, 0, 0, 0))\n","score21 = corpus_bleu(col_2, col_1, weights=(0, 1, 0, 0))\n","score31 = corpus_bleu(col_2, col_1, weights=(0, 0, 1, 0))\n","score41 = corpus_bleu(col_2, col_1, weights=(0, 0, 0, 1))\n","print(score11)\n","print(score21)\n","print(score31)\n","print(score41)"],"execution_count":null,"outputs":[]}]}